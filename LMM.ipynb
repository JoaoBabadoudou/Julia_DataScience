{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **régression à effets mixtes** (ou modèle linéaire à effets mixtes) est un modèle statistique qui combine des effets **fixes** et des effets **aléatoires**. Il est souvent utilisé pour analyser des données où les observations sont regroupées en sous-groupes, et où chaque groupe peut avoir une influence spécifique sur la variable à expliquer. \n",
    "\n",
    "Voyons maintenant la **logique** du modèle, étape par étape.\n",
    "\n",
    "### 1. **Pourquoi un modèle à effets mixtes ?**\n",
    "Dans de nombreux cas, les données que l’on veut modéliser ne sont pas indépendantes, c'est-à-dire qu'il existe des relations internes entre les données. Par exemple, dans une étude éducative, les élèves (observations) appartiennent à différentes écoles (groupes), et chaque école peut avoir une influence particulière sur les résultats des élèves. Un modèle de régression standard ne prendrait pas en compte cette variation spécifique à chaque école. C'est là que le modèle à effets mixtes entre en jeu.\n",
    "\n",
    "- **Effets fixes** : Ce sont les effets qui sont communs à toutes les observations. Par exemple, si l'on veut modéliser la relation entre les résultats des élèves et le nombre d'heures de cours, le coefficient de cette relation est fixe pour tous les élèves.\n",
    "  \n",
    "- **Effets aléatoires** : Ce sont des effets spécifiques à chaque groupe ou à chaque sous-groupe. Par exemple, chaque école peut avoir un \"intercept\" différent, reflétant des facteurs propres à l'école (comme la qualité de l'enseignement, les ressources, etc.) qui influencent les résultats des élèves.\n",
    "\n",
    "### 2. **Formule du modèle**\n",
    "Le modèle à effets mixtes s’écrit comme suit :\n",
    "\n",
    "\\[\n",
    "y = X \\beta + Zb + \\epsilon\n",
    "\\]\n",
    "\n",
    "- \\( y \\) : est le vecteur des observations (ou des résultats).\n",
    "- \\( X \\) : est la matrice des prédicteurs pour les effets fixes (les variables explicatives pour la partie fixe du modèle).\n",
    "- \\( \\beta \\) : est le vecteur des coefficients des effets fixes (comme dans une régression linéaire classique).\n",
    "- \\( Z \\) : est la matrice des prédicteurs pour les effets aléatoires (elle lie les observations à leurs groupes respectifs).\n",
    "- \\( b \\) : est le vecteur des coefficients des effets aléatoires. Ces effets sont considérés comme des variables aléatoires, souvent modélisées comme étant distribuées normalement, avec une moyenne de zéro et une variance \\(\\sigma_b^2\\).\n",
    "- \\( \\epsilon \\) : est l’erreur résiduelle (bruit), supposée également distribuée normalement avec une moyenne de zéro et une variance \\(\\sigma_\\epsilon^2\\).\n",
    "\n",
    "### 3. **Logique de génération des données (étape par étape)**\n",
    "Dans l'implémentation, nous avons d'abord généré des données pour simuler un problème à effets mixtes :\n",
    "\n",
    "1. **Groupes et effets aléatoires** : Nous générons 10 groupes (par exemple, 10 écoles), chacun ayant un **effet aléatoire** (ex. un intercept spécifique). Cet effet aléatoire est généré en tirant aléatoirement des valeurs selon une distribution normale centrée en zéro, avec une variance de 1.0 (paramètre \\( \\sigma_{\\text{random}} \\)).\n",
    "\n",
    "2. **Effets fixes** : Chaque observation a aussi un effet fixe : ici, il s’agit d’une relation linéaire entre une variable explicative \\( X \\) et la variable de réponse \\( y \\) (par exemple, plus l'élève passe de temps à étudier, plus ses résultats augmentent). Le coefficient associé à cet effet fixe (\\( \\beta \\)) est fixé à 2.0 dans l'exemple.\n",
    "\n",
    "3. **Ajout du bruit** : Enfin, on ajoute du **bruit** aléatoire à chaque observation, pour modéliser les erreurs ou les variations non expliquées par le modèle.\n",
    "\n",
    "La combinaison de ces trois composantes donne nos données synthétiques.\n",
    "\n",
    "### 4. **Initialisation des paramètres**\n",
    "Pour estimer notre modèle, nous devons initialiser plusieurs paramètres :\n",
    "- \\( \\beta \\) : Coefficient de l'effet fixe.\n",
    "- \\( b \\) : Coefficients des effets aléatoires pour chaque groupe.\n",
    "- \\( \\sigma_b \\) : Variance des effets aléatoires.\n",
    "- \\( \\sigma_\\epsilon \\) : Variance des résidus (erreurs).\n",
    "\n",
    "Ces paramètres sont initialisés avec des valeurs aléatoires avant de les optimiser.\n",
    "\n",
    "### 5. **Log-vraisemblance**\n",
    "Le modèle à effets mixtes est ajusté en maximisant une fonction de **log-vraisemblance**. Celle-ci mesure à quel point le modèle (avec les paramètres actuels) est compatible avec les données observées.\n",
    "\n",
    "La log-vraisemblance combine deux composantes :\n",
    "- **Contribution des effets aléatoires** : Cela inclut la manière dont les effets aléatoires sont distribués (on suppose qu’ils suivent une loi normale).\n",
    "- **Contribution des résidus** : C’est la partie qui mesure à quel point les résidus (différences entre les valeurs prédites par le modèle et les valeurs observées) suivent également une distribution normale.\n",
    "\n",
    "### 6. **Descente de gradient**\n",
    "Pour trouver les meilleurs paramètres (c'est-à-dire ceux qui maximisent la log-vraisemblance), nous utilisons la **descente de gradient**. Cette méthode ajuste progressivement les paramètres en calculant les dérivées de la log-vraisemblance par rapport à chaque paramètre, puis en les mettant à jour dans la direction qui améliore la log-vraisemblance.\n",
    "\n",
    "Concrètement, à chaque itération :\n",
    "- Les gradients (dérivées) de la log-vraisemblance sont calculés pour les paramètres \\( \\beta \\), \\( b \\), \\( \\sigma_b \\) et \\( \\sigma_\\epsilon \\).\n",
    "- Les paramètres sont ajustés selon ces gradients (à l’aide d’un facteur d’apprentissage `lr` qui contrôle l’ampleur de la mise à jour).\n",
    "- Le processus est répété jusqu’à convergence, c'est-à-dire jusqu’à ce que les mises à jour des paramètres deviennent très petites.\n",
    "\n",
    "### 7. **Visualisation**\n",
    "Une fois les paramètres ajustés, nous visualisons les résultats. Le graphique montre :\n",
    "- Les **données observées** : Ce sont les points de données bruts (la relation entre \\( X \\) et \\( y \\) pour chaque observation).\n",
    "- La **droite de régression des effets fixes** : C’est la droite correspondant à l'effet fixe global, qui est la même pour tous les groupes (ex. la relation générale entre \\( X \\) et \\( y \\) dans toutes les écoles).\n",
    "- Les **droites spécifiques aux groupes** : Chaque groupe a une droite de régression légèrement différente, car chaque groupe a un intercept différent dû à son effet aléatoire.\n",
    "\n",
    "### Pourquoi utiliser ce modèle ?\n",
    "Le modèle à effets mixtes est très utile lorsque vous avez des **groupes hiérarchiques** ou des **variations non indépendantes** dans vos données. Par exemple :\n",
    "- En éducation, les élèves peuvent être groupés par écoles, et chaque école peut avoir un effet différent sur la performance.\n",
    "- En médecine, les patients peuvent être groupés par hôpitaux ou médecins, avec chaque hôpital ou médecin ayant un effet spécifique.\n",
    "\n",
    "Le modèle à effets mixtes permet de capturer ces variations entre les groupes tout en estimant un effet fixe global.\n",
    "\n",
    "### Conclusion\n",
    "Le **modèle linéaire à effets mixtes** est une extension des modèles de régression classique qui permet de tenir compte de la variabilité entre groupes ou sous-groupes. Il est particulièrement adapté aux données hiérarchiques ou regroupées, où chaque groupe a ses propres caractéristiques tout en partageant une structure commune avec les autres groupes. Grâce à l'ajustement par descente de gradient, nous avons pu estimer à la fois les effets fixes et aléatoires, tout en maximisant la log-vraisemblance du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Random\n",
    "using Plots\n",
    "\n",
    "# Generate synthetic data for mixed effects model\n",
    "function generate_data(n_groups, n_per_group, σ_random, σ_noise)\n",
    "    Random.seed!(123)\n",
    "    n_samples = n_groups * n_per_group\n",
    "    group_effects = randn(n_groups) * σ_random\n",
    "    X = randn(n_samples)\n",
    "    β = 2.0\n",
    "    group = repeat(1:n_groups, inner=n_per_group)\n",
    "    y = [β * X[i] + group_effects[group[i]] + randn() * σ_noise for i in 1:n_samples]\n",
    "    return X, y, group\n",
    "end\n",
    "\n",
    "n_groups = 10\n",
    "n_per_group = 20\n",
    "σ_random = 1.0\n",
    "σ_noise = 0.5\n",
    "X, y, group = generate_data(n_groups, n_per_group, σ_random, σ_noise)\n",
    "\n",
    "# Initialize model parameters\n",
    "function initialize_params(n_groups)\n",
    "    β = randn()\n",
    "    b = randn(n_groups)\n",
    "    σ_b = 1.0\n",
    "    σ_noise = 0.5\n",
    "    return β, b, σ_b, σ_noise\n",
    "end\n",
    "\n",
    "β, b, σ_b, σ_noise = initialize_params(n_groups)\n",
    "\n",
    "# Log-likelihood function\n",
    "function log_likelihood(X, y, group, β, b, σ_b, σ_noise)\n",
    "    n = length(y)\n",
    "    group_effects = [b[group[i]] for i in 1:n]\n",
    "    residuals = y .- (X .* β .+ group_effects)\n",
    "    ll_random = -0.5 * sum((b ./ σ_b).^2)\n",
    "    ll_res\n",
    "\n",
    "end "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
